{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "import random as rand\n",
    "import scipy\n",
    "from matplotlib.pyplot import *\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mutual_info_score\n",
    "from sklearn.metrics import normalized_mutual_info_score\n",
    "import os\n",
    "from math import sqrt\n",
    "from math import sin\n",
    "import json\n",
    "from statistics import mean\n",
    "import entropy_estimators as ee\n",
    "import scipy.spatial as ss\n",
    "from scipy.special import digamma,gamma\n",
    "from math import log,pi\n",
    "import numpy.random as nr\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def random_sampling_normal_from_range(list_range,size):\n",
    "    m= mean(list_range)\n",
    "    s= abs((list_range[1] - m)/3)\n",
    "    return np.random.normal(m,s,size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#networkx 1.10\n",
    "def get_cyclic_net_v1(filename):\n",
    "    G=nx.read_edgelist(filename, comments='#', delimiter=\"\\t\", nodetype =str,  data=(('mode',str),), create_using=nx.DiGraph())\n",
    "    G.remove_nodes_from([\"Source\", \"Target\"])\n",
    "    selfloops=G.selfloop_edges()\n",
    "    G.remove_edges_from(G.selfloop_edges())\n",
    "    \n",
    "    \n",
    "    while 0 in G.in_degree().values() or 0 in G.out_degree().values():\n",
    "        nodes_to_remove=[node for node in G if G.in_degree(node) == 0 or G.out_degree(node) == 0]\n",
    "        G.remove_nodes_from(nodes_to_remove)\n",
    "        \n",
    "    selfloops_in_reservoir=[edge for edge in selfloops if edge[0] in G.nodes()]\n",
    "    G.add_edges_from(selfloops_in_reservoir)\n",
    "    return G\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#networkx 2.1\n",
    "def get_cyclic_net(filename):\n",
    "    G=nx.read_edgelist(filename, comments='#', delimiter=\"\\t\", nodetype =str,  data=(('mode',str),), create_using=nx.DiGraph())\n",
    "    G.remove_nodes_from([\"Source\", \"Target\"])\n",
    "    selfloops=G.selfloop_edges()\n",
    "    G.remove_edges_from(G.selfloop_edges())\n",
    "\n",
    "    while 0 in [d[1] for d in G.in_degree()] or 0 in [d[1] for d in G.out_degree()]:\n",
    "        nodes_to_remove=[node for node in G if G.in_degree(node) == 0 or G.out_degree(node) == 0]\n",
    "        G.remove_nodes_from(nodes_to_remove)\n",
    "        \n",
    "    selfloops_in_reservoir=[edge for edge in selfloops if edge[0] in G.nodes()]\n",
    "    G.add_edges_from(selfloops_in_reservoir)\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ESN(object):\n",
    "    def __init__(self, filename, in_size, out_size, spectral_radius):\n",
    "        self.res_size= self.build_adj_weighted_matrix(filename).shape[0]\n",
    "        self.in_size=in_size\n",
    "        self.out_size=out_size\n",
    "        self.spectral_radius= spectral_radius\n",
    "        self.W0=self.build_adj_weighted_matrix(filename)\n",
    "        self.W=None\n",
    "        self.Win=None\n",
    "        self.Wout=None\n",
    "        self.X=None\n",
    "        self.Y=None\n",
    "        self.x=np.zeros((self.res_size,1))\n",
    "        self.x0=np.insert(np.random.rand(self.res_size)*10,0,[1.0,1.0,1.0])\n",
    "        self.decay=random_sampling_normal_from_range([1/15,1/60],(self.res_size,1))\n",
    "        self.u=None\n",
    "        self.x_act=None\n",
    "\n",
    "    \n",
    "    def build_adj_weighted_matrix(self, filename):\n",
    "        #NETWORK v2.0\n",
    "        net=get_cyclic_net(filename)\n",
    "        for edge in net.edges(data=\"mode\", default=0):\n",
    "            source,target,mode=edge\n",
    "            if mode== \"+\":\n",
    "                net[source][target][\"weight\"]= rand.uniform(0,1)\n",
    "            elif mode== \"-\":\n",
    "                net[source][target][\"weight\"]= rand.uniform(0,-1)\n",
    "            elif mode== 0:\n",
    "                net[source][target][\"weight\"]= rand.uniform(-1,1)\n",
    "        return nx.to_numpy_matrix(net)\n",
    "    \n",
    "    def initialize(self): \n",
    "        np.random.seed(42)\n",
    "        self.Win=np.random.choice([-0.05,0.05], size=(self.res_size,1+self.in_size))\n",
    "        self.W0 = np.squeeze(np.asarray(self.W0))\n",
    "        rhoW0 = max(abs(scipy.linalg.eig(self.W0)[0]))\n",
    "        self.W= (self.spectral_radius/rhoW0)*self.W0\n",
    "        \n",
    "\n",
    "    def collect_states(self, data, init_len, train_len, a=0.3):\n",
    "        self.X=np.zeros((self.res_size+self.in_size+1, train_len-init_len))\n",
    "        for t in range(train_len):\n",
    "            u = data[t]\n",
    "            self.x = (1-a)*self.x + a*np.tanh( np.dot( self.Win, np.vstack((1,u)) ) + np.dot( self.W, self.x ) ) \n",
    "            if t >= init_len:\n",
    "                self.X[:,t-init_len]= np.vstack((1,u,self.x))[:,0]\n",
    "        \n",
    "        return self.X\n",
    "    \n",
    "    \n",
    "    def collect_states_derivative(self, a,b,c, init_len, train_len, test_len):\n",
    "        self.X=np.zeros((self.res_size+self.in_size+1, train_len-init_len))\n",
    "        t=np.arange(train_len+test_len)\n",
    "        uyz_x=scipy.integrate.odeint(self.dx_dt,self.x0,t,args=(a,b,c,self.decay))\n",
    "        self.u=uyz_x[:,0]\n",
    "        self.x_act=uyz_x[:,3:]\n",
    "        for t in range(init_len,train_len):\n",
    "            x_concat=self.x_act[t,:].reshape(self.x_act[t,:].shape[0],1)\n",
    "            u_concat=self.u[t]\n",
    "            self.X[:,t-init_len]= np.vstack((1,u_concat,x_concat))[:,0]\n",
    "               \n",
    "        return self.X\n",
    "    \n",
    "    def dx_dt(self, uyz_x,t,a,b,c,decay):\n",
    "        u=uyz_x[0]\n",
    "        y=uyz_x[1]\n",
    "        z=uyz_x[2]\n",
    "        x=np.array(uyz_x[3:]).reshape(self.res_size,1)\n",
    "       \n",
    "        du_dt=-z-y\n",
    "        dy_dt=u+a*y\n",
    "        dz_dt=b+z*(u-c)\n",
    "        dx_dt= np.tanh( np.dot( self.Win, np.vstack((1,u)) ) + np.dot( self.W, x ) ) - (decay * x)\n",
    "        \n",
    "        return np.insert(dx_dt,0,[du_dt,dy_dt,dz_dt])\n",
    "        \n",
    "    def calculate_weights(self, data, init_len, train_len,beta=1e-8 ):\n",
    "        Y=data[None,init_len+1:train_len+1]\n",
    "        X_T=self.X.T\n",
    "        self.Wout= np.dot ( np.dot(Y, X_T), np.linalg.inv(np.dot(self.X,X_T) + beta * np.eye(self.res_size+self.in_size+1)))\n",
    "        return self.Wout\n",
    "    \n",
    "    def calculate_weights_derivative(self,init_len, train_len, n, beta=1e-8 ):\n",
    "        Y=np.array([self.u[init_len+1-n:train_len+1-n]])\n",
    "        X_T=self.X.T\n",
    "        self.Wout= np.dot ( np.dot(Y, X_T), np.linalg.inv(np.dot(self.X,X_T) + beta * np.eye(self.res_size+self.in_size+1))) #w= y*x_t*(x*x_t + beta*I)^-1\n",
    "        return self.Wout\n",
    "    \n",
    "    def run_generative(self, data, test_len, train_len,a=0.3):\n",
    "        self.Y = np.zeros((self.out_size,test_len))\n",
    "        u = data[train_len]\n",
    "        for t in range(test_len):\n",
    "            self.x = (1-a)*self.x + a*np.tanh( np.dot( self.Win, np.vstack((1,u)) ) + np.dot( self.W, self.x ) ) \n",
    "            y = np.dot( self.Wout, np.vstack((1,u,self.x)) )\n",
    "            self.Y[:,t] = y\n",
    "            u = data[trainLen+t+1]\n",
    "            #u =y\n",
    "    \n",
    "    def run_predictive_derivative(self, a,b,c, test_len, train_len):\n",
    "        self.Y = np.zeros((self.out_size,test_len))\n",
    "        \n",
    "        for t in range(train_len,train_len+test_len):\n",
    "            x_concat=self.x_act[t,:].reshape(self.x_act[t,:].shape[0],1)\n",
    "            u_concat=self.u[t]\n",
    "            y = np.dot( self.Wout, np.vstack((1,u_concat,x_concat)) )\n",
    "            self.Y[:,t-train_len] = y\n",
    "           \n",
    "        \n",
    "        return self.Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#                                   FUNCTIONS                                    #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#NARMA \n",
    "def NARMA_task(steps, data, init_len, train_len):\n",
    "        Y=np.zeros(train_len)\n",
    "        for t in range(init_len,train_len):\n",
    "            Y[t]=0.3* Y[t-1] + 0.05*Y[t-1]*np.sum(Y[t-1:t-steps])+ 1.5*data[t-steps]*data[t-1]+0.1\n",
    "                \n",
    "        return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def testing_gene_net(directory,input_data,data):\n",
    "    csv_files= [file for file in os.listdir(directory) if file.startswith(\"network_edge_list\")]\n",
    "    print(csv_files)\n",
    "    MI_by_file={}\n",
    "    for file in csv_files:\n",
    "        filename=file[file.index(\"list\")+5:file.index(\".csv\")]\n",
    "        net=ESN(os.path.join(directory, file),1,1,0.95)\n",
    "        net.initialize()\n",
    "        net.collect_states(input_data,initLen,trainLen)\n",
    "        net.calculate_weights(input_data,initLen,trainLen)\n",
    "        net.run_generative(input_data,testLen,trainLen)\n",
    "        MI_by_file[filename]=memory_capacity_n(net.Y, data,100)\n",
    "        nrmse= sqrt(mean_squared_error(data[trainLen+1:trainLen+errorLen+1],net.Y[0,0:errorLen])/np.std(net.Y[0,0:errorLen]))\n",
    "        print(net.res_size, 'NRMSE = ' + str( nrmse ))\n",
    "        print(memory_capacity_n(net.Y, data,20))\n",
    "        \n",
    "    return MI_by_file\n",
    "        #plot( data[trainLen+1:trainLen+testLen+1], 'g' )\n",
    "        #plot( net.Y.T, 'b' )\n",
    "        #title('Target and generated signals $y(n)$ starting at $n=0$')\n",
    "        #legend(['Target signal', 'Free-running predicted signal'])\n",
    "        #show()\n",
    "      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def testing_gene_net_derivative(directory,a,b,c,n):\n",
    "    csv_files= [file for file in os.listdir(directory) if file.startswith(\"network_edge_list\")]\n",
    "    Y_by_file={}\n",
    "    X_by_file={}\n",
    "    MI_by_file={}\n",
    "    NRMSE_by_file={}\n",
    "    for file in csv_files:\n",
    "        print(file)\n",
    "        filename=file[file.index(\"list\")+5:file.index(\".csv\")]\n",
    "        net=ESN(os.path.join(directory, file),1,1,0.95)\n",
    "        net.initialize()\n",
    "        net.collect_states_derivative(a,b,c,initLen,trainLen,testLen)\n",
    "        net.calculate_weights_derivative(initLen,trainLen,n)\n",
    "        net.run_predictive_derivative(a,b,c,testLen,trainLen)\n",
    "        X_by_file[filename]=net.u\n",
    "        Y_by_file[filename]=net.Y\n",
    "        NRMSE_by_file[filename]=nrmse_n(net.Y,net.u)\n",
    "        MI_by_file[filename]=memory_capacity_n(net.Y, net.u,n)\n",
    "        print(nrmse(net.Y[0,0:errorLen],net.u[trainLen+1:trainLen+errorLen+1]))\n",
    "        print(net.res_size, \" FINISHED\")\n",
    "        \n",
    "        #figure(num=None, figsize=(10, 8), dpi=80, facecolor='w', edgecolor='k')\n",
    "        #plot( net.u[trainLen+1:trainLen+testLen+1], 'g' )\n",
    "        #plot( net.Y.T, 'b' )\n",
    "        #xlabel(\"time\")\n",
    "        #ylabel(\"signal\")\n",
    "        #title('Target and generated signals $y(n)$ starting at $n=0$ until $n=%s$' %testLen)\n",
    "        #legend(['Target signal', 'Free-running predicted signal'])\n",
    "        #savefig(\"plots-input-vs-output/%s_testLen\" %filename)\n",
    "        #show()\n",
    "        \n",
    "        #figure(num=None, figsize=(10, 8), dpi=80, facecolor='w', edgecolor='k')\n",
    "        #plot( net.u[trainLen+1:trainLen+50+1], 'g' )\n",
    "        #plot( net.Y.T[0:50], 'b' )\n",
    "        #xlabel(\"time\")\n",
    "        #ylabel(\"signal\")\n",
    "        #title('Target and generated signals $y(n)$ starting at $n=0$ until $n=50$')\n",
    "        #legend(['Target signal', 'Free-running predicted signal'])\n",
    "        #savefig(\"plots-input-vs-output/%s_50\" %filename)\n",
    "        #show()\n",
    "       \n",
    "  \n",
    "    return MI_by_file, X_by_file, Y_by_file, NRMSE_by_file\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def testing_gene_net_file(directory,file):\n",
    "    print(file)\n",
    "    filename=file[file.index(\"list\")+5:file.index(\".csv\")]\n",
    "    net=ESN(os.path.join(directory, file),1,1,0.95)\n",
    "    net.initialize()\n",
    "    net.collect_states(data,initLen,trainLen)\n",
    "    net.calculate_weights(data,initLen,trainLen)\n",
    "    net.run_generative(data,testLen,trainLen)\n",
    "    nrmse= sqrt(mean_squared_error(data[trainLen+1:trainLen+errorLen+1],net.Y[0,0:errorLen])/np.std(net.Y[0,0:errorLen]))\n",
    "    print(net.res_size, 'NRMSE = ' + str( nrmse ))\n",
    "    return memory_capacity_n(net.Y, data,100)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def testing_gene_net_derivative_file(directory,file):\n",
    "    print(file)\n",
    "    filename=file[file.index(\"list\")+5:file.index(\".csv\")]\n",
    "    net=ESN(os.path.join(directory, file),1,1,0.95)\n",
    "    net.initialize()\n",
    "    net.collect_states_derivative(a,b,c,initLen,trainLen,testLen)\n",
    "    net.calculate_weights_derivative(initLen,trainLen)\n",
    "    net.run_predictive_derivative(a,b,c,testLen,trainLen)\n",
    "    #nrmse= sqrt(mean_squared_error(net.u[trainLen+1:trainLen+errorLen+1],net.Y[0,0:errorLen])/np.std(net.Y[0,0:errorLen]))\n",
    "    #print(net.res_size, 'NRMSE = ' + str( nrmse ))\n",
    "    #plot(np.arange(trainLen+testLen+1),net.u)\n",
    "    #show()\n",
    "    return memory_capacity_n(net.Y,net.u,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def entropy(x,k=3,base=2):\n",
    "    \"\"\" The classic K-L k-nearest neighbor continuous entropy estimator\n",
    "         x should be a list of vectors, e.g. x = [[1.3],[3.7],[5.1],[2.4]]\n",
    "        if x is a one-dimensional scalar and we have four samples\n",
    "    \"\"\"\n",
    "    assert k <= len(x)-1 #\"Set k smaller than num. samples - 1\"\n",
    "    d = len(x[0])\n",
    "    N = len(x)\n",
    "    intens = 1e-10 #small noise to break degeneracy, see doc.\n",
    "    x = [list(p + intens*nr.rand(len(x[0]))) for p in x]\n",
    "    tree = ss.cKDTree(x)\n",
    "    nn = [tree.query(point,k+1,p=float('inf'))[0][k] for point in x]\n",
    "    const = digamma(N)-digamma(k) + d*log(2)\n",
    "    return (const + d*np.mean(list(map(log,nn)),dtype=np.float64))/log(base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def entropy_binning(c_xy):\n",
    "    c_normalized = c_xy/np.sum(c_xy)\n",
    "    c_normalized = c_normalized[np.nonzero(c_normalized)]\n",
    "    h = -sum(c_normalized * np.log(c_normalized))  \n",
    "    return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_MI_binning(x, y):\n",
    "    bins=sqrt(x.shape[0]/5)\n",
    "    c_xy = np.histogram2d(x, y, bins)[0]\n",
    "    mi = mutual_info_score(None, None, contingency=c_xy)\n",
    "    #mi = mutual_info_score(x,y)\n",
    "    return mi/entropy_binning(c_xy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_MI_npeet(x,y):\n",
    "    return ee.mi(x.reshape((x.shape[0],1)), y.reshape((y.shape[0],1)), base=2)/entropy(x.reshape((x.shape[0],1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def memory_capacity_n(Yt, Xt,n):\n",
    "    MI_i={}\n",
    "    for i in range(200+1):\n",
    "        MI_i[i]=calc_MI_npeet(Yt[0,300:900],Xt[300-i:900-i]) \n",
    "    \n",
    "    return MI_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def nrmse_n(Yt, Xt):\n",
    "    NRMSE_i={}\n",
    "    for i in range(51):\n",
    "        NRMSE_i[i]=nrmse(Yt[0,200:1000],Xt[200-i:1000-i]) \n",
    "    \n",
    "    return NRMSE_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def nrmse(y,x):\n",
    "    return sqrt(mean_squared_error(x,y))/np.std(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_MI_i(key,mi_dict,n):\n",
    "    x=[]\n",
    "    y=[]\n",
    "    for i,MI in mi_dict.items():\n",
    "        x.append(i)\n",
    "        y.append(MI)\n",
    "    plot(x,y,label=key)\n",
    "    plot(n,mi_dict[n],marker='o')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_MI_by_file(MI_by_file):\n",
    "    for key in MI_by_file.keys():\n",
    "        plot_MI_i(key, MI_by_file[key])\n",
    "    legend(loc='upper left')\n",
    "    show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#                                   TESTEOS                                      #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TESTEO get_cyclic_net\n",
    "G=get_cyclic_net_v1(os.path.join(\"Dataset1/\", \"network_edge_list_modENCODE.csv\"))\n",
    "len(G.nodes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TESTEO adjacency matrix\n",
    "net=ESN(os.path.join(\"Dataset1/\", \"network_edge_list_DBTBS.csv\"),1,1,0.95)\n",
    "net.W0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TESTEO initialize\n",
    "net.initialize()\n",
    "print(net.W.shape)\n",
    "print(max(abs(scipy.linalg.eig(net.W)[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TESTEO collect states\n",
    "net.collect_states_derivative(a,b,c, initLen, trainLen, testLen, n=2)\n",
    "net.X.shape\n",
    "net.X[:,7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#                             RESULTS                                            #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TRAINING AND TEST LENGHT\n",
    "errorLen = 500\n",
    "trainLen=9000\n",
    "testLen=1000\n",
    "initLen=200\n",
    "\n",
    "#Files\n",
    "csv_files=['network_edge_list_ENCODE.csv', 'network_edge_list_modENCODE.csv', 'network_edge_list_YEASTRACT.csv', 'network_edge_list_EcoCyc.csv', 'network_edge_list_DBTBS.csv']\n",
    "\n",
    "#parameters ROSSLER\n",
    "a=0.1\n",
    "b=0.1\n",
    "c=14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#MACKEY GLASS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"MACKEY GLASS\")\n",
    "data = np.loadtxt('MackeyGlass_t17.txt')\n",
    "MI=testing_gene_net(\"Dataset1/\",data,data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# NARMA TASK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "u_narma= [rand.uniform(0,0.5) for el in range(10501)]\n",
    "NARMA_result= NARMA_task(10,u_narma,initLen,len(data))\n",
    "NARMA_result[2000:4000]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"NARMA\")\n",
    "testing_gene_net(\"Dataset1/\",NARMA_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ROSSLER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"With derivatives\")\n",
    "MI_by_file, X_by_file, Y_by_file, NRMSE_by_file=testing_gene_net_derivative(\"Dataset1/\", a,b,c,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NRMSE_n_file={}\n",
    "    \n",
    "for n in [0,10,15,20,25,50]:\n",
    "    MI_by_file, X_by_file, Y_by_file, NRMSE_by_file=testing_gene_net_derivative(\"Dataset1/\", a,b,c,n)\n",
    "    \n",
    "    for key in NRMSE_by_file.keys():\n",
    "        NRMSE_n_file.setdefault(key,{})\n",
    "        NRMSE_n_file[key][n]= NRMSE_by_file[key]\n",
    "        \n",
    "    figure(num=None, figsize=(10, 8), dpi=80, facecolor='w', edgecolor='k')\n",
    "    title(\"n=\"+str(n))\n",
    "    plot_MI_by_file(MI_by_file)\n",
    "\n",
    "figure(num=None, figsize=(10, 8), dpi=80, facecolor='w', edgecolor='k')\n",
    "title(\"minimum half life 15 min\")\n",
    "plot_MI_by_file(NRMSE_n_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "network_edge_list_DBTBS.csv\n",
      "0.20355129316\n",
      "13  FINISHED\n",
      "network_edge_list_YEASTRACT.csv\n",
      "2.68371620022\n",
      "289  FINISHED\n",
      "network_edge_list_ENCODE.csv\n",
      "0.170806477442\n",
      "207  FINISHED\n",
      "network_edge_list_EcoCyc.csv\n",
      "0.116522730462\n",
      "70  FINISHED\n",
      "network_edge_list_modENCODE.csv\n"
     ]
    }
   ],
   "source": [
    "for n in [0,10,20,50,80,100]:\n",
    "    MI_by_file, X_by_file, Y_by_file, NRMSE_by_file=testing_gene_net_derivative(\"Dataset1/\", a,b,c,n)\n",
    "    figure(num=None, figsize=(10, 8), dpi=80, facecolor='w', edgecolor='k')\n",
    "    title(\"n=\"+str(n))\n",
    "    plot_MI_i(\"DBTBS\",NRMSE_by_file[\"DBTBS\"],n)\n",
    "    show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NRMSE_15min=NRMSE_by_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_MI_i(\"modENCODE\",NRMSE_5min[\"modENCODE\"])\n",
    "plot_MI_i(\"modENCODE\",NRMSE_15min[\"modENCODE\"])\n",
    "show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MI_by_file, X_by_file, Y_by_file, NRMSE_by_file=testing_gene_net_derivative(\"Dataset1/\", a,b,c,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
